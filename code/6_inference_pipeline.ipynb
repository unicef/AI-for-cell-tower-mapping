{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32459,"status":"ok","timestamp":1669069119028,"user":{"displayName":"Alejandro Saez","userId":"00374930392066440175"},"user_tz":300},"id":"6cgUuGjYwDmS","outputId":"822a1853-22a2-4e48-d889-de9602bd4bc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from PIL import Image\n","from matplotlib.pyplot import imshow\n","import numpy as np\n","from tqdm import tqdm as tqdm\n","\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"o1NbFLInzZKc"},"source":["# Inference pipeline"]},{"cell_type":"markdown","metadata":{"id":"7JnOfYbJzXK5"},"source":["### 0. Set up path structure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLS6qtGEw8uE"},"outputs":[],"source":["# Path that holds the raw images we want to make predictions for - 500k Brazil images for example\n","raw_img_directory = '/content/drive/MyDrive/UNICEF & NYU Giga initiative - data sharing/data/pipeline/raw'\n","# Path that will hold the resolution enhanced and 512x512 resized images \n","interim_directory = '/content/drive/MyDrive/UNICEF & NYU Giga initiative - data sharing/data/pipeline/interim'\n","# Path where trained models are stored\n","models_directory =  '/content/drive/MyDrive/UNICEF & NYU Giga initiative - data sharing/data/models'"]},{"cell_type":"markdown","metadata":{"id":"RBzOvrQny4hS"},"source":["### 1. Resolution enhancement"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_UPUtG0wy9zu"},"outputs":[],"source":["%cd /content\n","!rm -rf GFPGAN\n","!git clone https://github.com/TencentARC/GFPGAN.git\n","%cd GFPGAN\n","!pip install basicsr\n","!pip install facexlib\n","!pip install -r requirements.txt\n","!python setup.py develop\n","!pip install realesrgan\n","!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P experiments/pretrained_models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RAjknZZBw8q_"},"outputs":[],"source":["upscale = 4\n","version = 1.4\n","res_enh_cmd = f'inference_gfpgan.py --input \"{raw_img_directory}\" --output \"{interim_directory}\" --version {version} --upscale {upscale} --bg_upsampler realesrgan'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PT6Jj-yl4xO2"},"outputs":[],"source":["!rm -rf results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7bizODr4q5g"},"outputs":[],"source":["%run $res_enh_cmd"]},{"cell_type":"markdown","metadata":{"id":"CdJYK4HZzmP5"},"source":["### 2. Resizing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144198,"status":"ok","timestamp":1669066115495,"user":{"displayName":"Alejandro Saez","userId":"00374930392066440175"},"user_tz":300},"id":"1FWTqGPUzmi1","outputId":"817a0238-284e-438b-8657-dfc6eca38549"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 202/202 [02:24<00:00,  1.40it/s]\n"]}],"source":["# Create folder to store resized images within interim path\n","resized_imgs_path = os.path.join(f'{interim_directory}', 'resized_imgs')\n","if (not os.path.exists(resized_imgs_path)):\n","  os.mkdir(resized_imgs_path)\n","\n","# Define new size of images\n","newsize = (512, 512)\n","\n","# Iterate through the images in the restored_imgs path \n","for i in tqdm(os.listdir(os.path.join(interim_directory, 'restored_imgs'))):\n","  current_im = Image.open(os.path.join(interim_directory, 'restored_imgs', i))\n","  resized_im = current_im.resize(newsize)\n","  resized_im.save(os.path.join(resized_imgs_path, i), \"PNG\")"]},{"cell_type":"markdown","metadata":{"id":"fy0aZ-5R4Jzh"},"source":["### 3. Model execution"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QYE1PCG8C4nA"},"outputs":[],"source":["!git clone https://github.com/ultralytics/yolov5\n","!pip install -r yolov5/requirements.txt\n","!pip install pyyaml\n","!pip install layoutparser\n","\n","!nvcc --version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"H5I0NdTeQUAv","outputId":"174e5ff5-d9ef-42e4-c153-3c2d56abc352"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch:  1.12 ; cuda:  cu113\n","/content/GFPGAN/yolov5\n"]}],"source":["import torch\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","\n","%cd yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4_mdi-754KFT","outputId":"9939a640-2f0f-4c03-d10f-e23388ccdfe2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving in directory results\n"]}],"source":["import json\n","import yaml\n","import shutil\n","import glob\n","import re\n","from pathlib import Path\n","\n","def find_results(folder, path=interim_directory + '/results_([0-9]+)'):\n","  return re.findall(path, folder)\n","\n","# Create a yaml file with data configuration\n","dict_file = {\n","    'path': interim_directory,\n","    'inference': 'resized_imgs',\n","    'names': {0: 'all'}\n","}\n","with open(r'./data_config.yaml', 'w') as file:\n","    documents = yaml.dump(dict_file, file)\n","\n","# If overwrite = True -> delete current folder containing results and save new results in new created folder\n","# If overwrite = False -> create new results folder (results_n)\n","overwrite = True\n","if (overwrite == True) & (os.path.exists(os.path.join(interim_directory, 'results'))):\n","  shutil.rmtree(os.path.join(interim_directory, 'results'))\n","  fname='results'\n","else:\n","  result_folders = glob.glob(interim_directory + '/results*')\n","  if len(result_folders) == 0:\n","    fname='results'\n","  else:\n","    num_folders = [int(find_results(folder)[0]) for folder in result_folders if len(find_results(folder)) > 0]\n","    next_num = max(num_folders) + 1\n","    fname=f'results_{next_num}'\n","print(f'Saving in directory {fname}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PriqiaIWeg-Y"},"outputs":[],"source":["result_directory = os.path.join(interim_directory, fname)\n","!python detect.py --weights '/content/drive/MyDrive/UNICEF & NYU Giga initiative - data sharing/data/models/yolo_model_100_epoch_optim_hyperparam.pt' --data data_config.yaml --imgsz 512 --iou-thres 0.5 --conf-thres 0.5 --save-txt --name 'inference' --source '/content/drive/MyDrive/UNICEF & NYU Giga initiative - data sharing/data/pipeline/interim/resized_imgs'\n","# Saving YOLO files\n","shutil.copytree('runs/detect/inference', result_directory)"]},{"cell_type":"markdown","metadata":{"id":"e0MdevLZ4NeK"},"source":["### 4. Geo json mapping from bounding box prediction"]},{"cell_type":"markdown","metadata":{"id":"WZXpqZ_2pHKU"},"source":["#### 4.1 Convert from YOLO 2 COCO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDhI07OW4N2K"},"outputs":[],"source":["def yolo2coco(yolo_data, img_w=520, img_h=520):\n","  x_yolo = yolo_data[0]\n","  y_yolo = yolo_data[1]\n","  w_yolo = yolo_data[2]\n","  h_yolo = yolo_data[3]\n","  \n","  w_coco = w_yolo * img_w\n","  h_coco = h_yolo * img_h\n","  x_coco = x_yolo * img_w - w_coco/2\n","  y_coco = y_yolo * img_h - h_coco/2\n","  return [x_coco, y_coco, w_coco, h_coco]\n","\n","def create_coco_file(predn):\n","    # Save one JSON result {\"image_id\": 42, \"category_id\": 18, \"bbox\": [258.15, 41.29, 348.26, 243.78], \"score\": 0.236}\n","    jdict = []\n","    for key, values in predn.items():\n","        b = yolo2coco(values[1:])\n","        jdict.append({\n","            'image_id': key,\n","            'category_id': int(values[0]),\n","            'bbox': [round(x, 3) for x in b]\n","        })\n","    return jdict\n","\n","def read_yolo_file(path):\n","  path = Path(path)\n","  with open(path, 'rt') as fd:\n","    for line in fd.readlines():\n","        predn = line.split()\n","  predn = list(map(float, predn))\n","  image_id = int(path.stem) if path.stem.isnumeric() else path.stem\n","  return image_id, predn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUr42ccedNM-"},"outputs":[],"source":["label_directory = os.path.join(result_directory, 'labels')\n","yolo_files = glob.glob(os.path.join(label_directory,'*'))\n","predictions = {}\n","for path in yolo_files:\n","  image_id, predn = read_yolo_file(path)\n","  predictions[image_id] = predn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8MTuQQJdOQ0"},"outputs":[],"source":["coco_format = create_coco_file(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYi-lsh3ed1b"},"outputs":[],"source":["coco_path = os.path.join(label_directory, 'coco_labels.json')\n","with open(coco_path, 'w') as f:\n","    json.dump(coco_format, f)"]},{"cell_type":"markdown","metadata":{"id":"WW3sg1Z1pNys"},"source":["#### 4.2 Georreference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3753,"status":"ok","timestamp":1669060463493,"user":{"displayName":"Lorena Piedras","userId":"02478464441546641986"},"user_tz":300},"id":"gtOlc52TqVQs","outputId":"38629336-3de8-48e9-da11-7ada9fdb55e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: geopandas in /usr/local/lib/python3.7/dist-packages (0.10.2)\n","Requirement already satisfied: rasterio in /usr/local/lib/python3.7/dist-packages (1.2.10)\n","Requirement already satisfied: fiona>=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.22)\n","Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n","Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.5.post1)\n","Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.2.1)\n","Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n","Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.1.1)\n","Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (22.1.0)\n","Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2.5.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2022.9.24)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (0.7.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.6)\n","Requirement already satisfied: affine in /usr/local/lib/python3.7/dist-packages (from rasterio) (2.3.1)\n","Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n"]}],"source":["!pip install geopandas rasterio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VLTrSKkWpneA"},"outputs":[],"source":["import geopandas as gpd\n","import pandas as pd\n","from shapely.geometry import box\n","from shapely.affinity import affine_transform\n","from rasterio.transform import from_bounds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vr3A7aCFqM7M"},"outputs":[],"source":["def from_imgcoords_to_latlong(\n","  bbox_coords, img_lat_long, \n","  img_measurements=[512,512]\n","  ):\n","  \"\"\"\n","  Args:\n","    img_coords (list): list with [x_min, y_min, x_max, y_max]\n","    img_lat_long (list): lat long coordinates of the image with \n","    the format [top, left, bottom, rigth]\n","    img_measurements (list): [img_width, img_height]\n","  Returns:\n","    Returns a transformed geometry using an affine transformation matrix\n","  \"\"\"\n","  bbox = box(bbox_coords[0], bbox_coords[1], bbox_coords[2], bbox_coords[3])\n","  affine_obj = from_bounds(\n","      north = img_lat_long[0],\n","      west = img_lat_long[1], \n","      south = img_lat_long[2], \n","      east = img_lat_long[3], \n","      width = img_measurements[0], \n","      height = img_measurements[1]\n","      )\n","\n","  geom_bbox = affine_transform(\n","      bbox, \n","      [affine_obj.a, affine_obj.b,\n","       affine_obj.d, affine_obj.e,\n","       affine_obj.xoff, affine_obj.yoff]\n","       )\n","  return geom_bbox"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hojbvy65pPyD"},"outputs":[],"source":["# File with node_id column containing unique id and top, left, bottom right columns containing lat/long boundaries of the image\n","img_latlong_path = '/content/drive/MyDrive/UNICEF & NYU Giga initiative - data sharing/Satellite images/unfiltered_with_bboxes.csv'\n","img_latlong_data = pd.read_csv(img_latlong_path)\n","bbox_pred = json.load(open(coco_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JevEDmn1p2Gu"},"outputs":[],"source":["geom_list_geo = []\n","node_ids = []\n","for bbox in bbox_pred:\n","  # Getting node id\n","  node_id = bbox['image_id']\n","\n","  # Getting lat long of the image\n","  img_latlong = img_latlong_data.loc[\n","    img_latlong_data['node_id'] == node_id, \n","    ['top', 'left', 'bottom', 'right']\n","    ].to_numpy()\n","  if img_latlong.shape[0] == 0:\n","    raise ValueError(f\"Node id {node_id} doesn't exist\")\n","  if img_latlong.shape[0] > 1:\n","    raise ValueError('Node id tied to more than one image')\n","  img_latlong = img_latlong[0]\n","\n","  # Converting bbox from coco to xmin, ymin, xmax, ymax\n","  bbox_coco = bbox['bbox']\n","  bbox_kitti = [\n","      bbox_coco[0],\n","      bbox_coco[1],\n","      bbox_coco[0] + bbox_coco[2],\n","      bbox_coco[1] + bbox_coco[3]\n","      ]\n","\n","  # Transforming bbox into lat/long coords\n","  geom_bbox = from_imgcoords_to_latlong(\n","        bbox_kitti,\n","        img_latlong\n","    )\n","  geom_list_geo.append(geom_bbox)\n","  node_ids.append(node_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bxa1kfp7qxOq"},"outputs":[],"source":["geo_results_path = os.path.join(result_directory, 'geo_boxes.geojson')\n","crs = \"EPSG:4326\"\n","geo_df = gpd.GeoDataFrame(\n","    node_ids, \n","    columns=['node_id'],\n","    geometry=geom_list_geo,\n","    crs=crs\n","    )\n","# save geojson file\n","geo_df.to_file(\n","    geo_results_path\n","    )"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.13 ('cds-capstone')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.13"},"vscode":{"interpreter":{"hash":"e416b1e7dd84a4b2d7e958b86a1c3c56ef889e85ca273df49604efcb8011685e"}}},"nbformat":4,"nbformat_minor":0}
